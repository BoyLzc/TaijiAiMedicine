1303046
庞俊（1983—），男，湖北咸宁人，博士，副教授，主要研究方向为图数据管理、图挖掘、大数据管理和分析等。
PANG Jun, born in 1983, Ph.D., associate professor, senior member of CCF. His research interests include graph data management, graph mining, big data management and analysis, etc.
To further unlock the value of data elements, cross-domain sharing and circulation of graph data are imperative. However, these processes face critical privacy and security challenges. Existing graph generalization-based privacy preservation methods exhibit notable limitations, including excessive information loss in anonymized graphs and an inherent trade-off between privacy protection strength and data utility.
To address these issues, we propose KNCA-RL-CSD (K-Number Clustering Anonymization with Reinforcement Learning and Constructing Nodes with the Same Degree), a novel privacy preservation model. First, the model employs a multi-agent reinforcement learning algorithm based on learning automata to iteratively optimize node partitioning, significantly reducing information loss in anonymized graphs. Second, we introduce CSD (Constructing Nodes with the Same Degree), an edge perturbation method grounded in node-degree balancing. By minimizing edge modifications, CSD effectively resists structural inference attacks based on node degree analysis.
Extensive experiments on multiple real-world datasets demonstrate that KNCA-RL-CSD mitigates structural inference attacks while further reducing information loss. Compared to baseline methods, the model achieves improvements of 3%–12% in the Degree of Anonymization (DoA) and 2%–8% in Information Loss Efficiency (ILE), outperforming all existing approaches across key evaluation metrics.
To further unlock the value of data elements, cross-domain sharing and circulation of graph data are imperative, yet they raise critical privacy concerns. Existing graph generalization-based privacy-preserving methods suffer from three key limitations: (1) inappropriate cluster quantity selection, (2) excessive information loss in anonymized graphs, and (3) an inherent trade-off between privacy protection and data utility. To address these challenges, we propose LLM-GARL (Large Language Model-Enhanced Graph Anonymization via Reinforcement Learning), a novel privacy-preserving framework.
First, our method employs large language models (LLMs) to infer optimal cluster configurations and privacy parameters, achieving a balanced compromise between anonymization strength and information preservation. Second, we design a multi-agent reinforcement learning algorithm to iteratively optimize node partitioning, further minimizing information loss. Finally, we introduce a degree-aware edge perturbation mechanism that strategically modifies edges with minimal alterations to resist degree-based structural inference attacks.
Extensive experiments on real-world datasets demonstrate that LLM-GARL significantly reduces information loss while robustly defending against structural inference attacks. Compared to state-of-the-art methods, our model improves the Degree of Anonymization (DoA) by 6%-20% and Information Loss Efficiency (ILE) by 2%-13%, establishing a new benchmark for privacy-utility-balanced graph anonymization.